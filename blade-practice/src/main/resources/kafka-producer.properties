#kafka producer的配置，相信的信息可以在 org.apache.kafka.clients.producer.ProducerConfig 查到

#用于建立到Kafka集群的初始连接的主机/端口对列表。
#客户端将使用所有服务器，而不管这里为bootstrapping&mdash指定了哪些服务器;
#此列表只影响用于发现完整服务器集的初始主机。
#这个列表的形式应该是<code>host1:port1,host2:port2，…</code>。
#由于这些服务器仅用于初始连接以发现完整的集群成员关系(可能会动态更改)，
# 因此此列表不需要包含完整的服务器集(不过，在服务器关闭时，您可能需要多个服务器)。
bootstrap.servers=192.168.2.106:9092,192.168.2.152:9092,192.168.2.167:9092

#实现 org.apache.kafka.common.serialize.Serializer 接口的key的序列化器类。
key.serializer=org.apache.kafka.common.serialization.StringSerializer

#实现 org.apache.kafka.common.serialize.Serializer 接口的value的序列化器类。
value.serializer=org.apache.kafka.common.serialization.StringSerializer

#设置一个大于零的值将导致客户端重新发送任何发送失败的记录，并可能出现暂时错误。
#请注意，此重试与客户机在收到错误后重新发送记录没有什么不同。
#允许重试而不设置 "max.in.flight.requests.per.connection"为 1 ，可能会改变记录的顺序，
# 因为如果将两个批发送到单个partition，第一个批失败并重试，但第二个批成功，那么第二个批中的记录可能会首先出现。
#retries=0

#当向server发出请求时，这个字符串会发送给server。目的是能够追踪请求源头，以此来允许ip/port许可列表之外的一些应用可以发送信息。
# 这项应用可以设置任意字符串，因为没有任何功能性的目的，除了记录和跟踪。
client.id=bladeDemo

#此配置实际上代表了数据备份的可用性。
#acks=0： 设置为0表示producer不需要等待任何确认收到的信息。副本将立即加到socket buffer并认为已经发送。
# 没有任何保障可以保证此种情况下server已经成功接收数据，同时重试配置不会发生作用
#acks=1： 这意味着至少要等待leader已经成功将数据写入本地log，但是并没有等待所有follower是否成功写入。
# 这种情况下，如果follower没有成功备份数据，而此时leader又挂掉，则消息会丢失。
#acks=all： 这意味着leader需要等待所有备份都成功写入日志，这种策略会保证只要有一个备份存活就不会丢失数据。这是最强的保证。
#acks=1

#producer将试图批处理消息记录，以减少请求次数。这将改善client与server之间的性能。这项配置控制默认的批量处理消息字节数。
#batch.size=16384

#producer可以用来缓存数据的内存大小。如果数据产生速度大于向broker发送的速度，producer会阻塞或者抛出异常，
# 以“block.on.buffer.full”来表明。
#buffer.memory=33554432

#producer用于压缩数据的压缩类型。默认是无压缩。正确的选项值是none、gzip、snappy。压缩最好用于批量处理，批量处理消息越多，压缩性能越好。
#compression.type=none

#多久之后关闭空闲连接
#connections.max.idle.ms=540000

#当设置为“true”时，生产者将确保在流中准确地写入每个消息的一个副本。
#如果“false”，生产者重试由于代理失败等，可能会在流中写入重试消息的副本。
#注意，启用幂等性需要 max.in.flight.requests.per.connection 小于或等于5，
# retries 要大于0, acks 必须为'all'。
#如果用户没有显式地设置这些值，那么将选择合适的值。如果设置了不兼容的值，将抛出ConfigException。
#enable.idempotence=false


#interceptor.classes=null

#producer组将会汇总任何在请求与发送之间到达的消息记录一个单独批量的请求。
# 通常来说，这只有在记录产生速度大于发送速度的时候才能发生。
#linger.ms=0

#该配置控制 KafkaProducer.send()和 KafkaProducer.partitionsFor()将阻塞多长时间。
#这些方法可以被阻塞，因为缓冲区已满或元数据不可用。在用户提供的序列化程序或分区程序中的阻塞将不计入此超时。
#max.block.ms=60000

# 客户机在阻塞之前在单个连接上发送的未确认请求的最大数量。
# 注意，如果该设置被设置为大于1且发送失败，会有消息重排序的风险(即消息1可能后于消息2)
# 也就是 retries 参数大于0
#max.in.flight.requests.per.connection=5

#请求的最大字节数。这也是对最大记录尺寸的有效覆盖。注意：server具有自己对消息记录尺寸的覆盖，这些尺寸和这个设置不同。
# 此项设置将会限制producer每次批量发送请求的数目，以防发出巨量的请求。
#max.request.size=1048576
#metadata.max.age.ms=300000
#metric.reporters=
#metrics.num.samples=2
#metrics.recording.level=INFO
#metrics.sample.window.ms=30000
#实现Partitioner接口的分区器类。默认使用DefaultPartitioner来进行分区
#partitioner.class=org.apache.kafka.clients.producer.internals.DefaultPartitioner

#TCP send缓存大小，当发送数据时使用。
#send.buffer.bytes=131072

#TCP receive缓存大小，当阅读数据时使用。
#receive.buffer.bytes=32768
#reconnect.backoff.max.ms=1000
#reconnect.backoff.ms=50
#request.timeout.ms=30000
#retry.backoff.ms=100
#transactional.id=null
#transaction.timeout.ms=60000
#security.protocol=PLAINTEXT

# 下面是与kafka安全相关的参数
#sasl.jaas.config = null
#sasl.kerberos.kinit.cmd = /usr/bin/kinit
#sasl.kerberos.min.time.before.relogin = 60000
#sasl.kerberos.service.name = null
#sasl.kerberos.ticket.renew.jitter = 0.05
#sasl.kerberos.ticket.renew.window.factor = 0.8
#sasl.mechanism = GSSAPI
#ssl.cipher.suites = null
#ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
#ssl.endpoint.identification.algorithm = null
#ssl.key.password = null
#ssl.keymanager.algorithm = SunX509
#ssl.keystore.location = null
#ssl.keystore.password = null
#ssl.keystore.type = JKS
#ssl.protocol = TLS
#ssl.provider = null
#ssl.secure.random.implementation = null
#ssl.trustmanager.algorithm = PKIX
#ssl.truststore.location = null
#ssl.truststore.password = null
#ssl.truststore.type = JKS